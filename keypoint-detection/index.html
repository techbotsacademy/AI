<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Pose Detection with Grid Background</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
  <style>
    body {
      text-align: center;
      font-family: Arial, sans-serif;
      background: #f8f9fa;
    }
    h1 { color: #333; }
    #container {
      display: flex;
      justify-content: center;
      flex-wrap: wrap;
      gap: 20px;
      margin-top: 20px;
    }
    canvas, img {
      border: 2px solid #ccc;
      border-radius: 5px;
      max-width: 400px;
    }
    pre {
      text-align: left;
      background: #222;
      color: #0f0;
      padding: 10px;
      border-radius: 5px;
      overflow-x: auto;
      max-height: 400px;
      width: 350px;
    }
    #loader {
      display: none;
      font-style: italic;
      color: #555;
    }
  </style>
</head>
<body>
  <h1>Pose Detection with Grid Background</h1>
  <input type="file" id="imageUpload" accept="image/*" />
  <p id="loader">Loading model and detecting pose...</p>

  <div id="container">
    <div>
      <h3>Original Image</h3>
      <!-- Default image from your upload -->
      <img id="inputImage" src="default.png" crossorigin="anonymous" />
    </div>
    <div>
      <h3>Pose Keypoints (Grid)</h3>
      <canvas id="outputCanvas"></canvas>
    </div>
    <div>
      <h3>Numeric Keypoints</h3>
      <pre id="keypointsData"></pre>
    </div>
  </div>

  <script>
    let net;

    async function loadModel() {
      document.getElementById('loader').style.display = 'block';
      net = await posenet.load();
      document.getElementById('loader').style.display = 'none';
      console.log('PoseNet model loaded.');
    }

    function drawGrid(ctx, width, height, step = 50) {
      ctx.strokeStyle = '#e0e0e0';
      ctx.lineWidth = 0.5;
      for (let x = 0; x < width; x += step) {
        ctx.beginPath();
        ctx.moveTo(x, 0);
        ctx.lineTo(x, height);
        ctx.stroke();
      }
      for (let y = 0; y < height; y += step) {
        ctx.beginPath();
        ctx.moveTo(0, y);
        ctx.lineTo(width, y);
        ctx.stroke();
      }
    }

    async function detectPose(imageElement) {
      const canvas = document.getElementById('outputCanvas');
      const ctx = canvas.getContext('2d');
      canvas.width = imageElement.width;
      canvas.height = imageElement.height;

      document.getElementById('loader').style.display = 'block';
      const pose = await net.estimateSinglePose(imageElement, { flipHorizontal: false });

      // Draw grid
      drawGrid(ctx, canvas.width, canvas.height, 50);

      // Draw image slightly transparent
      ctx.globalAlpha = 0.85;
      ctx.drawImage(imageElement, 0, 0, imageElement.width, imageElement.height);
      ctx.globalAlpha = 1.0;

      // Draw keypoints
      pose.keypoints.forEach(kp => {
        if (kp.score > 0.5) {
          ctx.beginPath();
          ctx.arc(kp.position.x, kp.position.y, 5, 0, 2 * Math.PI);
          ctx.fillStyle = 'red';
          ctx.fill();
          ctx.strokeStyle = '#fff';
          ctx.lineWidth = 1;
          ctx.stroke();
        }
      });

      document.getElementById('keypointsData').textContent = JSON.stringify(pose.keypoints, null, 2);
      document.getElementById('loader').style.display = 'none';
    }

    // Handle new image uploads
    document.getElementById('imageUpload').addEventListener('change', (event) => {
      const file = event.target.files[0];
      if (!file) return;

      const img = document.getElementById('inputImage');
      const reader = new FileReader();
      reader.onload = function(e) {
        img.src = e.target.result;
        img.onload = () => detectPose(img);
      };
      reader.readAsDataURL(file);
    });

    // Load model and run on default image
    loadModel().then(() => {
      const defaultImg = document.getElementById('inputImage');
      defaultImg.onload = () => detectPose(defaultImg);
    });
  </script>
</body>
</html>
